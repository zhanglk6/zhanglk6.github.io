---
title: "Covariance-Driven Regression Trees: Reducing Overfitting in CART"
collection: publications
category: manuscripts
permalink: /publication/2025-07-29-CovRT
excerpt: ' Propose a complementary approach by introducing a covariance-driven splitting
 criterion for regression trees (CovRT). This method is more robust to overfitting than
 the empirical risk minimization criterion used in CART, as it produces more balanced
 and stable splits and more effectively identify covariates with true signals.'
date: 2025-07-29
venue: ''
paperurl: ''
citation: ''
---
Decision trees are powerful machine learning algorithms, widely used in fields such as economics and medicine for their simplicity and interpretability. However, decision trees such as CART are prone to overfitting, especially when grown deep or the sample size is small. Conventional methods to reduce overfitting include pre-pruning and post-pruning, which constrain the growth of uninformative branches. In this paper, we propose a complementary approach by introducing a covariance-driven splitting criterion for regression trees (CovRT). This method is more robust to overfitting than the empirical risk minimization criterion used in CART, as it produces more balanced and stable splits and more effectively identify covariates with true signals. We establish the consistency of CovRT and proves that its predictive accuracy is comparable to that of CART in high-dimensional settings. We find that CovRT achieves superior prediction accuracy compared to CART in both simulations and real-world tasks. In particular, it reduces prediction risk by approximately 24% on the Boston Housing dataset using a much shallower tree. 
In addition, it improves interpretability of tree models in two ways: first, each split is guided by a clear and interpretable target parameter; second, it often produces shallower models that are easier to interpret.
